#!/usr/bin/env python3

import argparse
import difflib
import json
import hashlib
import os
import re
import subprocess
import sys
import tomllib
import urllib.request
from io import BytesIO
from zipfile import ZipFile


def get_latest_run(owner: str, repo: str, branch: str, workflow_id: int) -> dict:
    req = urllib.request.Request(
        f"https://api.github.com/repos/{owner}/{repo}/actions/workflows/{workflow_id}/runs?branch={branch}&event=push&status=completed&per_page=1&exclude_pull_requests=true"
    )
    req.add_header("Accept", "application/vnd.github+json")
    req.add_header("X-GitHub-Api-Version", "2022-11-28")
    with urllib.request.urlopen(req) as f:
        return json.load(f)["workflow_runs"][0]


def get_current_run_id(owner: str, repo: str, cask: str) -> int:
    return int(
        re.findall(
            rf"\"https:\/\/nightly\.link\/{owner}\/{repo}\/actions\/runs\/([0-9]+)\/",
            cask,
        )[0]
    )


def get_artifact_links(run: dict, requested_artifacts: dict) -> dict:
    req = urllib.request.Request(run["artifacts_url"])
    req.add_header("Accept", "application/vnd.github+json")
    req.add_header("X-GitHub-Api-Version", "2022-11-28")
    with urllib.request.urlopen(req) as f:
        artifact_resp = json.load(f)["artifacts"]

    artifacts = {}
    for artifact in artifact_resp:
        for requested_artifact in requested_artifacts:
            if re.match(requested_artifact, artifact["name"]):
                artifacts[requested_artifact] = {
                    "url": f"https://nightly.link/{run['head_repository']['full_name']}/actions/runs/{run['id']}/{artifact['name']}.zip",
                    "digest": artifact["digest"],
                }

    return artifacts


def get_architecture() -> str:
    architecture_aliases = {"arm64": "arm", "x86_64": "intel"}

    machine = os.uname().machine
    return architecture_aliases[machine]


def check_artifacts(
    cask_artifacts: dict, artifact_links: dict, get_version: str
) -> str:
    architecture = get_architecture()

    for k, v in cask_artifacts.items():
        url = artifact_links[v]["url"]
        hash_algorithm, digest = artifact_links[v]["digest"].split(":")
        hasher = hashlib.new(hash_algorithm)

        print(f"Downloading {url}...", end="", flush=True)
        with urllib.request.urlopen(url) as f:
            data = f.read()

        hasher.update(data)
        if hasher.hexdigest() != digest:
            print(" bad hash")
            sys.exit(1)
        else:
            print(" hash ok")

        if k == architecture or k == "universal":
            local_vars = {"zipfp": ZipFile(BytesIO(data))}
            exec(get_version, locals=local_vars)
            version = local_vars["version"]

    return version


def update_cask(
    cask: str,
    cask_path: str,
    version: str,
    cask_artifacts: dict,
    artifact_links: dict,
    dry_run: bool,
):
    new_cask = re.sub(r"(version\s+\")(.*)(\")", rf"\g<1>{version}\g<3>", cask)

    for k, v in cask_artifacts.items():
        if k == "universal":
            update_regex = r"(url\s+\")(.*)(\"\s+)sha256(\s+\")([0-9a-f]*)(\")"
        else:
            update_regex = (
                rf"(on_{k}\s+do\s+url\s+\")(.*)(\"\s+)sha256(\s+\")([0-9a-f]*)(\")"
            )

        url = artifact_links[v]["url"]
        hash_algorithm, digest = artifact_links[v]["digest"].split(":")
        new_cask = re.sub(
            update_regex,
            rf"\g<1>{url}\g<3>{hash_algorithm}\g<4>{digest}\g<6>",
            new_cask,
        )

    if dry_run:
        delta = difflib.unified_diff(
            cask.splitlines(keepends=True),
            new_cask.splitlines(keepends=True),
            fromfile=f"a/{cask_path}",
            tofile=f"b/{cask_path}",
        )
        sys.stdout.writelines(delta)
    else:
        with open(cask_path, "w") as f:
            f.write(new_cask)


def commit_cask_update(cask_path: str, cask_name: str, version: str):
    proc = subprocess.run(
        ["git", "commit", cask_path, "-m", f"{cask_name}: {version}", "-q"],
        capture_output=True,
    )
    if proc.returncode != 0:
        print(
            f"error: git exited with non-zero status {proc.returncode}", file=sys.stderr
        )
        sys.exit(1)


def main():
    parser = argparse.ArgumentParser(
        prog="cask-update-gh", description="Nightly Cask updater (for GitHub Actions)"
    )

    parser.add_argument("cask", help="path to Cask file")
    parser.add_argument("config", help="path to config file")
    parser.add_argument(
        "-c",
        "--commit",
        action="store_true",
        help="commit changes to the Cask file",
    )
    parser.add_argument(
        "-n",
        "--dry-run",
        action="store_true",
        help="show what edits would be made to the Cask file",
    )

    args = parser.parse_args()
    cask_path = args.cask
    config_path = args.config
    dry_run = args.dry_run
    commit = args.commit

    if commit:
        if dry_run:
            print(
                "error: --commit and --dry-run are mutually exclusive", file=sys.stderr
            )
            sys.exit(1)

        proc = subprocess.run(["git", "diff-index", "--exit-code", "HEAD", cask_path])
        if proc.returncode != 0:
            print(f"warning: {cask_path} has uncommitted changes")

    with open(cask_path) as f:
        cask = f.read()

    matches = re.search(r"cask\s+\"(.+)\"(.|\n)+version\s+\"(.+)\"", cask)
    cask_name = matches[1]
    current_version = matches[3]

    with open(config_path, "rb") as f:
        config = tomllib.load(f)

    run = get_latest_run(
        config["owner"], config["repo"], config["branch"], config["action_id"]
    )

    current_run_id = get_current_run_id(config["owner"], config["repo"], cask)
    if run["id"] == current_run_id:
        print(f"{cask_path} is up-to-date")
        sys.exit(0)

    artifact_links = get_artifact_links(run, config["artifacts"].values())
    new_version = check_artifacts(
        config["artifacts"], artifact_links, config["get_version"]
    )

    update_cask(
        cask, cask_path, new_version, config["artifacts"], artifact_links, dry_run
    )
    if commit:
        commit_cask_update(cask_path, cask_name, new_version)

    print(f"{cask_name}: {current_version} â†’ {new_version}")


main()
